{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-BeZ0mhTEZT"
   },
   "source": [
    "# hw2: Решающие деревья\n",
    "\n",
    "*Спасибо великому курсу великого Евгения Соколова*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l790O-S-TEZU"
   },
   "source": [
    "### О задании\n",
    "\n",
    "Задание состоит из двух разделов:\n",
    "1. В первом разделе вы научитесь применять деревья из sklearn для задачи классификации. Вы посмотрите какие разделяющие поверхности деревья строят для различных датасетов и проанализируете их зависимость от различных гиперпараметров.\n",
    "2. Во втором разделе вы попробуете реализовать свое решающее дерево и сравните его со стандартное имплементацией из sklearn. Вы также протестируете деревья на более сложных датасетах и сравните различные подходы к кодированию категориальных признаков.\n",
    "\n",
    "Все данные, на которых будут обучаться модели, вы можете найти на диске.\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов. Неэффективная и/или неоригинальная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Заполненный ноутбук ```hw2-trees.ipynb``` и модуль с реализованными функциями и классами ```hw2code.py``` необходимо загрузить на свой Github. Затем нужно оставить комментарий в Google-таблице с оценками в столбце <<hw2>> в строке со своей фамилией о том, что вы выполнили работу с указанием ника на Kaggle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjUoF1GZTEZW"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/psutil/_psutil_osx.abi3.so' could not be imported from '/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/psutil/_psutil_osx.abi3.so, 0x0002'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from matplotlib.colors import Colormap, ListedColormap\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXPLGqNCTEZY"
   },
   "source": [
    "# 1. Решающие деревья. Визуализация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUjqXVx6TEZY"
   },
   "source": [
    "В этой части мы рассмотрим два простых двумерных датасета сделанных с помощью `make_moons`, `make_circles` и посмотрим как ведет себя разделяющая поверхность в зависимости от различных гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZTll755TEZZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "datasets = [\n",
    "    make_circles(noise=0.2, factor=0.5, random_state=42),\n",
    "    make_moons(noise=0.2, random_state=42),\n",
    "    make_classification(n_classes=3, n_clusters_per_class=1, n_features=2, class_sep=.8, random_state=3,\n",
    "                        n_redundant=0., )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RazQQTYvTEZZ"
   },
   "outputs": [],
   "source": [
    "palette = sns.color_palette(n_colors=3)\n",
    "cmap = ListedColormap(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-I8-BM9fTEZa"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "for i, (x, y) in enumerate(datasets):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.scatter(x[:, 0], x[:, 1], c=y, cmap=cmap, alpha=.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-IG5UiBTEZa"
   },
   "source": [
    "__Задание 1. (1 балл)__\n",
    "\n",
    "Для каждого датасета обучите решающее дерево с параметрами по умолчанию, предварительно разбив выборку на обучающую и тестовую. Постройте разделящие поверхности (для этого воспользуйтесь функцией `plot_surface`, пример ниже). Посчитайте accuracy на обучающей и тестовой выборках. Сильно ли деревья переобучились?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBttFqh-TEZb"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/psutil/_psutil_osx.abi3.so' could not be imported from '/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/psutil/_psutil_osx.abi3.so, 0x0002'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "def plot_surface(clf, X, y):\n",
    "    plot_step = 0.01\n",
    "    palette = sns.color_palette(n_colors=len(np.unique(y)))\n",
    "    cmap = ListedColormap(palette)\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=cmap, alpha=0.3)\n",
    "\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap, alpha=.7,\n",
    "                edgecolors=np.array(palette)[y], linewidths=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DcfPPap5TEZb"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X, y = datasets[2]\n",
    "lr  = LinearRegression().fit(X, y)\n",
    "plot_surface(lr, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ujG9UUxTTEZc"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "for i, (X, y) in enumerate(datasets):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plot_surface(clf, X_train, y_train)\n",
    "    plt.title(f'Dataset {i+1}\\nTrain Acc: {train_acc:.3f}, Test Acc: {test_acc:.3f}')\n",
    "    \n",
    "    print(f\"Dataset {i+1}:\")\n",
    "    print(f\"  Train accuracy: {train_acc:.4f}\")\n",
    "    print(f\"  Test accuracy: {test_acc:.4f}\")\n",
    "    print(f\"  Overfitting: {'Yes' if train_acc > test_acc + 0.1 else 'No'}\")\n",
    "    print()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UDg3DZKTEZc"
   },
   "source": [
    "__Ответ:__\n",
    "\n",
    "Деревья с параметрами по умолчанию показывают сильное переобучение на всех трех датасетах. Это видно по тому, что accuracy на обучающей выборке близка к 1.0, в то время как на тестовой выборке она ниже. Деревья строят очень сложные разделяющие поверхности, которые идеально разделяют обучающие данные, но плохо обобщаются на новые данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LddFdX_VTEZc"
   },
   "source": [
    "__Задание 2. (1.5 балла)__\n",
    "\n",
    "Попробуйте перебрать несколько параметров для регуляризации (напр. `max_depth`, `min_samples_leaf`). Для каждого набора гиперпараметров постройте разделяющую поверхность, выведите обучающую и тестовую ошибки. Можно делать кросс-валидацию или просто разбиение на трейн и тест, главное делайте каждый раз одинаковое разбиение, чтобы можно было корректно сравнивать (помните же, что итоговое дерево сильно зависит от небольшого изменения обучающей выборки?). Проследите как меняется разделяющая поверхность и обобщающая способность. Почему так происходит, одинаково ли изменение для разных датасетов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKJZfzVDTEZd"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "max_depths = [1, 3, 5, 10, None]\n",
    "min_samples_leafs = [1, 5, 10, 20]\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "for dataset_idx, (X, y) in enumerate(datasets):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Dataset {dataset_idx + 1}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    print(\"\\nЭксперимент 1: Варьирование max_depth (min_samples_leaf=1)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(max_depths), figsize=(20, 4))\n",
    "    if len(max_depths) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, max_depth in enumerate(max_depths):\n",
    "        clf = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=1, random_state=random_state)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = clf.predict(X_train)\n",
    "        y_test_pred = clf.predict(X_test)\n",
    "        \n",
    "        train_acc = accuracy_score(y_train, y_train_pred)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "        \n",
    "        axes[idx].set_title(f'max_depth={max_depth}\\nTrain: {train_acc:.3f}, Test: {test_acc:.3f}')\n",
    "        plot_surface(clf, X_train, y_train)\n",
    "        axes[idx].set_xlabel('')\n",
    "        axes[idx].set_ylabel('')\n",
    "        \n",
    "        print(f\"  max_depth={max_depth:5s}: Train Acc={train_acc:.4f}, Test Acc={test_acc:.4f}\")\n",
    "    \n",
    "    plt.suptitle(f'Dataset {dataset_idx + 1}: Влияние max_depth', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nЭксперимент 2: Варьирование min_samples_leaf (max_depth=None)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(min_samples_leafs), figsize=(20, 4))\n",
    "    if len(min_samples_leafs) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, min_samples_leaf in enumerate(min_samples_leafs):\n",
    "        clf = DecisionTreeClassifier(max_depth=None, min_samples_leaf=min_samples_leaf, random_state=random_state)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = clf.predict(X_train)\n",
    "        y_test_pred = clf.predict(X_test)\n",
    "        \n",
    "        train_acc = accuracy_score(y_train, y_train_pred)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "        \n",
    "        axes[idx].set_title(f'min_samples_leaf={min_samples_leaf}\\nTrain: {train_acc:.3f}, Test: {test_acc:.3f}')\n",
    "        plot_surface(clf, X_train, y_train)\n",
    "        axes[idx].set_xlabel('')\n",
    "        axes[idx].set_ylabel('')\n",
    "        \n",
    "        print(f\"  min_samples_leaf={min_samples_leaf:3d}: Train Acc={train_acc:.4f}, Test Acc={test_acc:.4f}\")\n",
    "    \n",
    "    plt.suptitle(f'Dataset {dataset_idx + 1}: Влияние min_samples_leaf', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQGcNWj-TEZd"
   },
   "source": [
    "__Ответ:__\n",
    "\n",
    "При увеличении `max_depth` разделяющая поверхность становится более сложной и извилистой. При малых значениях (1-3) дерево строит простые границы, что приводит к недообучению. При больших значениях (10, None) дерево переобучается, идеально разделяя обучающие данные, но плохо обобщаясь.\n",
    "\n",
    "При увеличении `min_samples_leaf` разделяющая поверхность становится более гладкой и простой. Это предотвращает переобучение, но при слишком больших значениях может привести к недообучению.\n",
    "\n",
    "Для разных датасетов влияние параметров различается:\n",
    "- Для `make_circles` и `make_moons` (нелинейно разделимые) нужны более глубокие деревья или больше листьев для хорошего разделения\n",
    "- Для `make_classification` (линейно разделимый) даже неглубокие деревья работают хорошо\n",
    "\n",
    "В целом, регуляризация через `max_depth` и `min_samples_leaf` помогает найти баланс между сложностью модели и обобщающей способностью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gALYvCrTEZd"
   },
   "source": [
    "# 2. Решающие деревья своими руками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8juQjFKTEZd"
   },
   "source": [
    "В этой части вам нужно реализовать свой класс для обучения решающего дерева в задаче бинарной классификации с возможностью обработки вещественных и категориальных признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eEp7M9ATEZe"
   },
   "source": [
    "__Задание 3. (1.5 балл)__\n",
    "\n",
    "Реализуйте функцию find_best_split из модуля hw2code.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJrV4F3JTEZe"
   },
   "source": [
    "__Задание 4. (0.5 балла)__\n",
    "\n",
    "Загрузите таблицу students.csv (это немного преобразованный датасет [User Knowledge](https://archive.ics.uci.edu/ml/datasets/User+Knowledge+Modeling)). В ней признаки объекта записаны в первых пяти столбцах, а в последнем записана целевая переменная (класс: 0 или 1). Постройте на одном изображении пять кривых \"порог — значение критерия Джини\" для всех пяти признаков. Отдельно визуализируйте scatter-графики \"значение признака — класс\" для всех пяти признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7w-m-u9TEZe"
   },
   "outputs": [],
   "source": [
    "from hw2code import find_best_split\n",
    "\n",
    "students_df = pd.read_csv('datasets/students.csv')\n",
    "X_students = students_df.iloc[:, :5].values\n",
    "y_students = students_df.iloc[:, 5].values\n",
    "\n",
    "print(f\"Размер датасета: {X_students.shape}\")\n",
    "print(f\"Классы: {np.unique(y_students)}\")\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "for feature_idx in range(5):\n",
    "    feature_vector = X_students[:, feature_idx]\n",
    "    thresholds, ginis, threshold_best, gini_best = find_best_split(feature_vector, y_students)\n",
    "    \n",
    "    if len(thresholds) > 0:\n",
    "        plt.plot(thresholds, ginis, marker='o', markersize=3, label=f'Признак {feature_idx + 1}', linewidth=2)\n",
    "        if threshold_best is not None:\n",
    "            plt.scatter([threshold_best], [gini_best], s=100, marker='*', zorder=5)\n",
    "\n",
    "plt.xlabel('Порог', fontsize=12)\n",
    "plt.ylabel('Критерий Джини', fontsize=12)\n",
    "plt.title('Кривые \"порог — значение критерия Джини\" для всех признаков', fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "for feature_idx in range(5):\n",
    "    plt.subplot(2, 3, feature_idx + 4)\n",
    "    feature_vector = X_students[:, feature_idx]\n",
    "    plt.scatter(feature_vector[y_students == 0], y_students[y_students == 0], \n",
    "                alpha=0.6, label='Класс 0', s=30)\n",
    "    plt.scatter(feature_vector[y_students == 1], y_students[y_students == 1], \n",
    "                alpha=0.6, label='Класс 1', s=30)\n",
    "    plt.xlabel(f'Признак {feature_idx + 1}', fontsize=10)\n",
    "    plt.ylabel('Класс', fontsize=10)\n",
    "    plt.title(f'Признак {feature_idx + 1}', fontsize=11)\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Информация о лучших разбиениях:\")\n",
    "print(\"=\"*80)\n",
    "for feature_idx in range(5):\n",
    "    feature_vector = X_students[:, feature_idx]\n",
    "    thresholds, ginis, threshold_best, gini_best = find_best_split(feature_vector, y_students)\n",
    "    \n",
    "    if threshold_best is not None:\n",
    "        print(f\"\\nПризнак {feature_idx + 1}:\")\n",
    "        print(f\"  Лучший порог: {threshold_best:.4f}\")\n",
    "        print(f\"  Лучший критерий Джини: {gini_best:.6f}\")\n",
    "        print(f\"  Количество порогов: {len(thresholds)}\")\n",
    "    else:\n",
    "        print(f\"\\nПризнак {feature_idx + 1}: невозможно найти разбиение\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUQ4vjR0TEZf"
   },
   "source": [
    "__Задание 5. (0.5 балла)__\n",
    "\n",
    "Исходя из кривых значений критерия Джини, по какому признаку нужно производить деление выборки на два поддерева? Согласуется ли этот результат с визуальной оценкой scatter-графиков? Как бы охарактеризовали вид кривой для \"хороших\" признаков, по которым выборка делится почти идеально? Чем отличаются кривые для признаков, по которым деление практически невозможно?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFg9VPmuTEZf"
   },
   "source": [
    "**Ответ:**\n",
    "\n",
    "Исходя из кривых значений критерия Джини, деление выборки нужно производить по признаку с максимальным значением критерия Джини (наименьшим по модулю, так как критерий отрицательный). Обычно это признак, у которого кривая Джини имеет наиболее выраженный максимум.\n",
    "\n",
    "Для \"хороших\" признаков, по которым выборка делится почти идеально, кривая Джини имеет четко выраженный максимум, значение которого близко к 0 (или даже положительное, если мы используем прирост). Scatter-график для таких признаков показывает четкое разделение классов по значениям признака.\n",
    "\n",
    "Для признаков, по которым деление практически невозможно, кривая Джини будет плоской, без выраженных максимумов, а значения критерия будут близки к минимальным (наиболее отрицательным). Scatter-график для таких признаков показывает сильное перекрытие классов.\n",
    "\n",
    "Результаты согласуются: если кривая Джини показывает хорошее разбиение, то и на scatter-графике видно разделение классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_0CMUJyTEZf"
   },
   "source": [
    "__Задание 6. (1.5 балла).__\n",
    "\n",
    "Разберитесь с уже написанным кодом в классе DecisionTree модуля hw2code.py. Найдите ошибки в реализации метода \\_fit_node. Напишите функцию \\_predict_node.\n",
    "\n",
    " Построение дерева осуществляется согласно базовому жадному алгоритму, предложенному в лекции. Выбор лучшего разбиения необходимо производить по критерию Джини. Критерий останова: все объекты в листе относятся к одному классу или ни по одному признаку нельзя разбить выборку. Ответ в листе: наиболее часто встречающийся класс в листе. Для категориальных признаков выполняется преобразование, описанное в лекции в разделе «Учет категориальных признаков»."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCAEfUz2TEZf"
   },
   "source": [
    "__Задание 7. (0.5 балла)__\n",
    "\n",
    "Протестируйте свое решающее дерево на датасете [mushrooms](https://archive.ics.uci.edu/ml/datasets/Mushroom). Вам нужно скачать таблицу agaricus-lepiota.data (лежит на гитхабе вместе с заданием), прочитать ее с помощью pandas, применить к каждому столбцу LabelEncoder (из sklearn), чтобы преобразовать строковые имена категорий в натуральные числа. Первый столбец — это целевая переменная (e — edible, p — poisonous) Мы будем измерять качество с помощью accuracy, так что нам не очень важно, что будет классом 1, а что — классом 0. Обучите решающее дерево на половине случайно выбранных объектов (признаки в датасете категориальные) и сделайте предсказания для оставшейся половины. Вычислите accuracy.\n",
    "\n",
    "У вас должно получиться значение accuracy, равное единице (или очень близкое к единице), и не очень глубокое дерево."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOzzO5SfTEZg"
   },
   "outputs": [],
   "source": [
    "from hw2code import DecisionTree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mushrooms_df = pd.read_csv('datasets/agaricus-lepiota.data', header=None)\n",
    "\n",
    "print(f\"Размер датасета: {mushrooms_df.shape}\")\n",
    "print(f\"Первые несколько строк:\")\n",
    "print(mushrooms_df.head())\n",
    "\n",
    "le_dict = {}\n",
    "X_mushrooms_encoded = mushrooms_df.iloc[:, 1:].copy()\n",
    "y_mushrooms = mushrooms_df.iloc[:, 0].copy()\n",
    "\n",
    "for col in X_mushrooms_encoded.columns:\n",
    "    le = LabelEncoder()\n",
    "    X_mushrooms_encoded[col] = le.fit_transform(X_mushrooms_encoded[col].astype(str))\n",
    "    le_dict[col] = le\n",
    "\n",
    "le_target = LabelEncoder()\n",
    "y_mushrooms_encoded = le_target.fit_transform(y_mushrooms.astype(str))\n",
    "\n",
    "print(f\"\\nКлассы целевой переменной: {le_target.classes_}\")\n",
    "print(f\"Кодированные классы: {np.unique(y_mushrooms_encoded)}\")\n",
    "\n",
    "X_mushrooms = X_mushrooms_encoded.values\n",
    "y_mushrooms = y_mushrooms_encoded\n",
    "\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(X_mushrooms))\n",
    "split_idx = len(indices) // 2\n",
    "train_indices = indices[:split_idx]\n",
    "test_indices = indices[split_idx:]\n",
    "\n",
    "X_train = X_mushrooms[train_indices]\n",
    "X_test = X_mushrooms[test_indices]\n",
    "y_train = y_mushrooms[train_indices]\n",
    "y_test = y_mushrooms[test_indices]\n",
    "\n",
    "print(f\"\\nРазмер обучающей выборки: {X_train.shape}\")\n",
    "print(f\"Размер тестовой выборки: {X_test.shape}\")\n",
    "\n",
    "feature_types = ['categorical'] * X_train.shape[1]\n",
    "tree = DecisionTree(feature_types=feature_types)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = tree.predict(X_train)\n",
    "y_test_pred = tree.predict(X_test)\n",
    "\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\nРезультаты:\")\n",
    "print(f\"  Train accuracy: {train_acc:.6f}\")\n",
    "print(f\"  Test accuracy: {test_acc:.6f}\")\n",
    "\n",
    "def get_tree_depth(node, depth=0):\n",
    "    if node.get(\"type\") == \"terminal\":\n",
    "        return depth\n",
    "    else:\n",
    "        left_depth = get_tree_depth(node.get(\"left_child\", {}), depth + 1)\n",
    "        right_depth = get_tree_depth(node.get(\"right_child\", {}), depth + 1)\n",
    "        return max(left_depth, right_depth)\n",
    "\n",
    "tree_depth = get_tree_depth(tree._tree)\n",
    "print(f\"  Глубина дерева: {tree_depth}\")\n",
    "\n",
    "def count_nodes(node):\n",
    "    if node.get(\"type\") == \"terminal\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 1 + count_nodes(node.get(\"left_child\", {})) + count_nodes(node.get(\"right_child\", {}))\n",
    "\n",
    "num_nodes = count_nodes(tree._tree)\n",
    "print(f\"  Количество узлов: {num_nodes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RClb2IAyTEZg"
   },
   "source": [
    "__Задание 8. (бонус, 1 балл)__\n",
    "\n",
    "Реализуйте в классе DecisionTree поддержку параметров max_depth, min_samples_split и min_samples_leaf по аналогии с DecisionTreeClassifier. Постройте графики зависимости качества предсказания в зависимости от этих параметров для набора данных tic-tac-toe (см. следующий пункт)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35i9HYPDTEZg"
   },
   "source": [
    "__Задание 9. (2 балла)__\n",
    "\n",
    "Загрузите следующие наборы данных (напомним, что pandas умеет загружать файлы по url, в нашем случае это файл \\*.data), предварительно ознакомившись с описанием признаков и целевой переменной в каждом из них (она записаны в Data Folder, в файле *.names): \n",
    "* [mushrooms](https://archive.ics.uci.edu/ml/datasets/Mushroom) (загрузили в предыдущем пункте, классы записаны в нулевом столбце)\n",
    "* [tic-tac-toe](https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame) (классы записаны в последнем столбце, датасет лежит на гитхабе вместе с заданием)\n",
    "* [cars](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation) (классы записаны в последнем столбце, считаем что unacc, acc — это класс 0, good, vgood — класс 1)\n",
    "* [nursery](https://archive.ics.uci.edu/ml/datasets/Nursery) (классы записаны в последнем столбце, считаем, что not_recom и recommend — класс 0, very_recom, priority, spec_prior — класс 1).\n",
    "\n",
    "Закодируйте категориальные признаки, использовав LabelEncoder. С помощью cross_val_score (cv=10) оцените accuracy на каждом из этих наборов данных следующих алгоритмов:\n",
    "* DecisionTree, считающий все признаки вещественными\n",
    "* DecisionTree, считающий все признаки категориальными\n",
    "* DecisionTree, считающий все признаки вещественными + one-hot-encoding всех признаков\n",
    "* DecisionTreeClassifier из sklearn. Запишите результат в pd.DataFrame (по строкам — наборы данных, по столбцам — алгоритмы).\n",
    "\n",
    "Рекомендации:\n",
    "* Чтобы cross_val_score вычисляла точность, нужно передать scoring=make_scorer(accuracy_score), обе фукнции из sklearn.metrics.\n",
    "* Если вам позволяет память (а она скорее всего позволяет), указывайте параметр sparse=False в OneHotEncoder (если вы, конечно, используете его). Иначе вам придется добиваться того, чтобы ваша реализация дерева умела работать с разреженными матрицами (что тоже, в целом, не очень сложно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzHWYQYlTEZg"
   },
   "outputs": [],
   "source": [
    "from hw2code import DecisionTree\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier as SklearnDecisionTreeClassifier\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ЗАДАНИЕ 8: Графики зависимости качества от параметров для tic-tac-toe\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "tic_tac_toe_df = pd.read_csv('datasets/tic-tac-toe-endgame.csv', header=None)\n",
    "X_ttt = tic_tac_toe_df.iloc[:, :-1]\n",
    "y_ttt = tic_tac_toe_df.iloc[:, -1]\n",
    "\n",
    "le_ttt = {}\n",
    "X_ttt_encoded = X_ttt.copy()\n",
    "for col in X_ttt_encoded.columns:\n",
    "    le = LabelEncoder()\n",
    "    X_ttt_encoded[col] = le.fit_transform(X_ttt_encoded[col].astype(str))\n",
    "    le_ttt[col] = le\n",
    "\n",
    "le_target_ttt = LabelEncoder()\n",
    "y_ttt_encoded = le_target_ttt.fit_transform(y_ttt.astype(str))\n",
    "\n",
    "X_ttt_array = X_ttt_encoded.values\n",
    "y_ttt_array = y_ttt_encoded\n",
    "\n",
    "max_depths_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None]\n",
    "min_samples_splits_range = [2, 5, 10, 20, 50]\n",
    "min_samples_leafs_range = [1, 2, 5, 10, 20]\n",
    "\n",
    "scores_max_depth = []\n",
    "for max_depth in max_depths_range:\n",
    "    tree = DecisionTree(feature_types=['categorical'] * X_ttt_array.shape[1], \n",
    "                       max_depth=max_depth)\n",
    "    scores = cross_val_score(tree, X_ttt_array, y_ttt_array, cv=10, \n",
    "                            scoring=make_scorer(accuracy_score))\n",
    "    scores_max_depth.append(scores.mean())\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot([str(d) if d is not None else 'None' for d in max_depths_range], \n",
    "         scores_max_depth, marker='o')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy (CV)')\n",
    "plt.title('Зависимость accuracy от max_depth')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "scores_min_samples_split = []\n",
    "for min_samples_split in min_samples_splits_range:\n",
    "    tree = DecisionTree(feature_types=['categorical'] * X_ttt_array.shape[1], \n",
    "                       min_samples_split=min_samples_split)\n",
    "    scores = cross_val_score(tree, X_ttt_array, y_ttt_array, cv=10, \n",
    "                            scoring=make_scorer(accuracy_score))\n",
    "    scores_min_samples_split.append(scores.mean())\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(min_samples_splits_range, scores_min_samples_split, marker='o')\n",
    "plt.xlabel('min_samples_split')\n",
    "plt.ylabel('Accuracy (CV)')\n",
    "plt.title('Зависимость accuracy от min_samples_split')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "scores_min_samples_leaf = []\n",
    "for min_samples_leaf in min_samples_leafs_range:\n",
    "    tree = DecisionTree(feature_types=['categorical'] * X_ttt_array.shape[1], \n",
    "                       min_samples_leaf=min_samples_leaf)\n",
    "    scores = cross_val_score(tree, X_ttt_array, y_ttt_array, cv=10, \n",
    "                            scoring=make_scorer(accuracy_score))\n",
    "    scores_min_samples_leaf.append(scores.mean())\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(min_samples_leafs_range, scores_min_samples_leaf, marker='o')\n",
    "plt.xlabel('min_samples_leaf')\n",
    "plt.ylabel('Accuracy (CV)')\n",
    "plt.title('Зависимость accuracy от min_samples_leaf')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ЗАДАНИЕ 9: Тестирование на 4 датасетах с разными кодировками\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def prepare_mushrooms():\n",
    "    df = pd.read_csv('datasets/agaricus-lepiota.data', header=None)\n",
    "    X = df.iloc[:, 1:]\n",
    "    y = df.iloc[:, 0]\n",
    "    \n",
    "    le_dict = {}\n",
    "    X_encoded = X.copy()\n",
    "    for col in X_encoded.columns:\n",
    "        le = LabelEncoder()\n",
    "        X_encoded[col] = le.fit_transform(X_encoded[col].astype(str))\n",
    "        le_dict[col] = le\n",
    "    \n",
    "    le_target = LabelEncoder()\n",
    "    y_encoded = le_target.fit_transform(y.astype(str))\n",
    "    \n",
    "    return X_encoded.values, y_encoded, le_dict\n",
    "\n",
    "def prepare_tic_tac_toe():\n",
    "    df = pd.read_csv('datasets/tic-tac-toe-endgame.csv', header=None)\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    le_dict = {}\n",
    "    X_encoded = X.copy()\n",
    "    for col in X_encoded.columns:\n",
    "        le = LabelEncoder()\n",
    "        X_encoded[col] = le.fit_transform(X_encoded[col].astype(str))\n",
    "        le_dict[col] = le\n",
    "    \n",
    "    le_target = LabelEncoder()\n",
    "    y_encoded = le_target.fit_transform(y.astype(str))\n",
    "    \n",
    "    return X_encoded.values, y_encoded, le_dict\n",
    "\n",
    "def prepare_cars():\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\"\n",
    "    df = pd.read_csv(url, header=None)\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    y_binary = y.apply(lambda x: 0 if x in ['unacc', 'acc'] else 1)\n",
    "    \n",
    "    le_dict = {}\n",
    "    X_encoded = X.copy()\n",
    "    for col in X_encoded.columns:\n",
    "        le = LabelEncoder()\n",
    "        X_encoded[col] = le.fit_transform(X_encoded[col].astype(str))\n",
    "        le_dict[col] = le\n",
    "    \n",
    "    return X_encoded.values, y_binary.values, le_dict\n",
    "\n",
    "def prepare_nursery():\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/nursery/nursery.data\"\n",
    "    df = pd.read_csv(url, header=None)\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    y_binary = y.apply(lambda x: 0 if x in ['not_recom', 'recommend'] else 1)\n",
    "    \n",
    "    le_dict = {}\n",
    "    X_encoded = X.copy()\n",
    "    for col in X_encoded.columns:\n",
    "        le = LabelEncoder()\n",
    "        X_encoded[col] = le.fit_transform(X_encoded[col].astype(str))\n",
    "        le_dict[col] = le\n",
    "    \n",
    "    return X_encoded.values, y_binary.values, le_dict\n",
    "\n",
    "datasets_info = {\n",
    "    'mushrooms': prepare_mushrooms,\n",
    "    'tic-tac-toe': prepare_tic_tac_toe,\n",
    "    'cars': prepare_cars,\n",
    "    'nursery': prepare_nursery\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for dataset_name, prepare_func in datasets_info.items():\n",
    "    print(f\"\\nОбработка датасета: {dataset_name}\")\n",
    "    X, y, le_dict = prepare_func()\n",
    "    print(f\"  Размер: {X.shape}, Классы: {np.unique(y)}\")\n",
    "    \n",
    "    dataset_results = {}\n",
    "    \n",
    "    print(\"  Тестирование: DecisionTree (real features)...\")\n",
    "    tree_real = DecisionTree(feature_types=['real'] * X.shape[1])\n",
    "    scores = cross_val_score(tree_real, X, y, cv=10, scoring=make_scorer(accuracy_score))\n",
    "    dataset_results['DecisionTree (real)'] = scores.mean()\n",
    "    print(f\"    Accuracy: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "    \n",
    "    print(\"  Тестирование: DecisionTree (categorical features)...\")\n",
    "    tree_cat = DecisionTree(feature_types=['categorical'] * X.shape[1])\n",
    "    scores = cross_val_score(tree_cat, X, y, cv=10, scoring=make_scorer(accuracy_score))\n",
    "    dataset_results['DecisionTree (categorical)'] = scores.mean()\n",
    "    print(f\"    Accuracy: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "    \n",
    "    print(\"  Тестирование: DecisionTree (real + one-hot)...\")\n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "    X_ohe = ohe.fit_transform(X)\n",
    "    tree_ohe = DecisionTree(feature_types=['real'] * X_ohe.shape[1])\n",
    "    scores = cross_val_score(tree_ohe, X_ohe, y, cv=10, scoring=make_scorer(accuracy_score))\n",
    "    dataset_results['DecisionTree (real + OHE)'] = scores.mean()\n",
    "    print(f\"    Accuracy: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "    \n",
    "    print(\"  Тестирование: sklearn DecisionTreeClassifier...\")\n",
    "    sklearn_tree = SklearnDecisionTreeClassifier(random_state=42)\n",
    "    scores = cross_val_score(sklearn_tree, X, y, cv=10, scoring=make_scorer(accuracy_score))\n",
    "    dataset_results['sklearn DecisionTree'] = scores.mean()\n",
    "    print(f\"    Accuracy: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "    \n",
    "    results[dataset_name] = dataset_results\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ИТОГОВАЯ ТАБЛИЦА РЕЗУЛЬТАТОВ\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.round(4))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyHrtXW0TEZh"
   },
   "source": [
    "__Задание 10. (1 балла)__\n",
    "\n",
    "Проанализируйте результаты эксперимента. \n",
    "Одинаково ли для разных наборов данных ранжируются алгоритмы? \n",
    "Порассуждайте, почему так происходит. \n",
    "\n",
    "Обратите внимание на значение признаков в разных наборах данных. \n",
    "Присутствует ли в результатах какая-то компонента случайности? \n",
    "Можно ли повлиять на нее и улушить работу алгоритмов?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_H9e_xANTEZh"
   },
   "source": [
    "**Ответ:**\n",
    "\n",
    "**Анализ результатов:**\n",
    "\n",
    "1. **Ранжирование алгоритмов для разных датасетов:**\n",
    "   - Для разных наборов данных алгоритмы ранжируются по-разному, что связано с природой признаков в каждом датасете.\n",
    "   - На датасетах с категориальными признаками (mushrooms, tic-tac-toe) лучше работает подход с категориальными признаками или one-hot encoding.\n",
    "   - На датасетах, где признаки можно интерпретировать как вещественные (cars, nursery), подход с вещественными признаками может работать сопоставимо.\n",
    "\n",
    "2. **Почему так происходит:**\n",
    "   - **DecisionTree (real)**: Интерпретирует категориальные значения как вещественные числа, что может привести к неправильному упорядочиванию категорий.\n",
    "   - **DecisionTree (categorical)**: Правильно обрабатывает категориальные признаки, используя преобразование на основе соотношения классов.\n",
    "   - **DecisionTree (real + OHE)**: One-hot encoding создает много признаков, что может привести к переобучению, но также дает больше гибкости.\n",
    "   - **sklearn DecisionTree**: Оптимизированная реализация с различными эвристиками, обычно показывает хорошие результаты.\n",
    "\n",
    "3. **Компонента случайности:**\n",
    "   - В результатах присутствует компонента случайности из-за кросс-валидации и случайного разбиения данных.\n",
    "   - Можно повлиять на нее, фиксируя random_state и используя стратифицированную кросс-валидацию.\n",
    "   - Для улучшения работы алгоритмов можно использовать:\n",
    "     - Настройку гиперпараметров (max_depth, min_samples_split, min_samples_leaf)\n",
    "     - Ансамбли методов (Random Forest, Gradient Boosting)\n",
    "     - Более сложные методы кодирования категориальных признаков (target encoding, embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsGY78W5TEZh"
   },
   "source": [
    "**Впечатления от задания:**\n",
    "\n",
    "Это задание было очень полезным для понимания работы решающих деревьев. Особенно интересно было:\n",
    "\n",
    "1. **Реализация с нуля**: Создание собственного класса DecisionTree помогло глубоко понять алгоритм построения деревьев, критерий Джини и обработку категориальных признаков.\n",
    "\n",
    "2. **Визуализация**: Построение разделяющих поверхностей наглядно показало, как деревья переобучаются и как регуляризация влияет на форму границ решений.\n",
    "\n",
    "3. **Сравнение подходов**: Эксперименты с разными способами кодирования категориальных признаков (real, categorical, one-hot) показали важность правильной обработки данных.\n",
    "\n",
    "4. **Практический опыт**: Работа с реальными датасетами из UCI Machine Learning Repository дала опыт подготовки данных и оценки моделей.\n",
    "\n",
    "Задание хорошо структурировано и охватывает как теоретические, так и практические аспекты работы с решающими деревьями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G__5d2pkTEZh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

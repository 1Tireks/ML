{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0wmsZc8_Rh_"
   },
   "source": [
    "# hw3: Обучение без учителя\n",
    "\n",
    "*Спасибо ещё одному великому курсу mlcourse.ai и авторам: Ольга Дайховская (@aiho в Slack ODS), Юрий Кашницкий (@yorko в Slack ODS).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMgQJwKY_RiC"
   },
   "source": [
    "### О задании\n",
    "\n",
    "В этом задании мы разберемся с тем, как работают методы снижения размерности и кластеризации данных. Заодно еще раз попрактикуемся в\n",
    "задаче классификации.\n",
    "\n",
    "Мы будем работать с набором данных [Samsung Human Activity Recognition](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones). Данные поступают с акселерометров и гироскопов мобильных телефонов Samsung Galaxy S3 (подробнее про признаки – по ссылке на UCI выше), также известен вид активности человека с телефоном в кармане – ходил ли он, стоял, лежал, сидел или шел вверх/вниз по лестнице.\n",
    "\n",
    "Вначале мы представим, что вид активности нам неизвестнен, и попробуем кластеризовать людей чисто на основе имеющихся признаков. Затем решим задачу определения вида физической активности именно как задачу классификации.\n",
    "\n",
    "**Заполните код в клетках (где написано \"Ваш код здесь\") и ответьте на вопросы, выделив ответ полужирным** (``` **выделить двойными звёздочками** ```).\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Вам необходимо ответить на 10 вопросов и выполнить 2 задания. Каждое из заданий и вопросов имеет определенную «стоимость» (указана в скобках). Максимально допустимая оценка за работу — 10 баллов. Неэффективная и/или неоригинальная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Заполненный ноутбук ```hw3-unsupervised.ipynb``` необходимо загрузить на свой Github. Затем нужно оставить комментарий в Google-таблице с оценками в столбце \"hw3\" в строке со своей фамилией о том, что вы выполнили работу и оставить ссылку на ноутбук.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WBw44GRl_RiC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.style.use(['seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans, SpectralClustering, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "RANDOM_STATE = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOhZ7oNL_RiD"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    X_train = np.loadtxt(\"../../data/samsung_HAR/samsung_train.txt\")\n",
    "    y_train = np.loadtxt(\"../../data/samsung_HAR/samsung_train_labels.txt\").astype(int)\n",
    "    X_test = np.loadtxt(\"../../data/samsung_HAR/samsung_test.txt\")\n",
    "    y_test = np.loadtxt(\"../../data/samsung_HAR/samsung_test_labels.txt\").astype(int)\n",
    "except FileNotFoundError:\n",
    "    try:\n",
    "        X_train = np.loadtxt(\"datasets/samsung_HAR/samsung_train.txt\")\n",
    "        y_train = np.loadtxt(\"datasets/samsung_HAR/samsung_train_labels.txt\").astype(int)\n",
    "        X_test = np.loadtxt(\"datasets/samsung_HAR/samsung_test.txt\")\n",
    "        y_test = np.loadtxt(\"datasets/samsung_HAR/samsung_test_labels.txt\").astype(int)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Файлы данных не найдены. Пожалуйста, скачайте данные Samsung HAR и поместите их в папку datasets/samsung_HAR/\")\n",
    "        print(\"Ссылка: https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tGbiGAqb_RiE"
   },
   "outputs": [],
   "source": [
    "# Проверим размерности\n",
    "assert(X_train.shape == (7352, 561) and y_train.shape == (7352,))\n",
    "assert(X_test.shape == (2947, 561) and y_test.shape == (2947,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3j_7FO5_RiE"
   },
   "source": [
    "Для кластеризации нам не нужен вектор ответов, поэтому будем работать с объединением обучающей и тестовой выборок. Объедините *X_train* с *X_test*, а *y_train* – с *y_test*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Xr3U8zP_RiE"
   },
   "outputs": [],
   "source": [
    "X = np.vstack([X_train, X_test])\n",
    "y = np.hstack([y_train, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZ1nAJvG_RiE"
   },
   "source": [
    "Определим число уникальных значений меток целевого класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K_W0pWW4_RiF"
   },
   "outputs": [],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IV5QnohU_RiF"
   },
   "outputs": [],
   "source": [
    "n_classes = np.unique(y).size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_YLlAy5_RiF"
   },
   "source": [
    "[Эти метки соответствуют:](https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.names)\n",
    "- 1 - ходьбе\n",
    "- 2 - подъему вверх по лестнице\n",
    "- 3 - спуску по лестнице\n",
    "- 4 - сидению\n",
    "- 5 - стоянию\n",
    "- 6 - лежанию\n",
    "\n",
    "*уж простите, если звучание этих существительных кажется корявым :)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gnstoPS_RiF"
   },
   "source": [
    "Отмасштабируйте выборку с помощью `StandardScaler` с параметрами по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KotDuwa_RiF"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Y1PvGKu_RiG"
   },
   "source": [
    "Понижаем размерность с помощью PCA, оставляя столько компонент, сколько нужно для того, чтобы объяснить как минимум 90% дисперсии исходных (отмасштабированных) данных. Используйте отмасштабированную выборку и зафиксируйте random_state (константа RANDOM_STATE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJirforB_RiG"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.9, random_state=RANDOM_STATE)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzCQ0b1A_RiG"
   },
   "source": [
    "**Вопрос 1:** (1 балл)\n",
    "\n",
    "Какое минимальное число главных компонент нужно выделить, чтобы объяснить 90% дисперсии исходных (отмасштабированных) данных?\n",
    "\n",
    "**Варианты:**\n",
    "- 56\n",
    "- **65**\n",
    "- 66\n",
    "- 193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7CbSdf1X_RiG"
   },
   "outputs": [],
   "source": [
    "n_components_90 = pca.n_components_\n",
    "print(f\"Количество компонент для 90% дисперсии: {n_components_90}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thia_iUQ_RiG"
   },
   "source": [
    "**Вопрос 2:** (0.5 баллов)\n",
    "\n",
    "Сколько процентов дисперсии приходится на первую главную компоненту? Округлите до целых процентов.\n",
    "\n",
    "**Варианты:**\n",
    "- 45\n",
    "- **51**\n",
    "- 56\n",
    "- 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D1x6jIQ7_RiG"
   },
   "outputs": [],
   "source": [
    "first_component_variance = pca.explained_variance_ratio_[0] * 100\n",
    "print(f\"Дисперсия первой главной компоненты: {first_component_variance:.2f}%\")\n",
    "print(f\"Округлено до целых: {int(round(first_component_variance))}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3oU8PfY4_RiG"
   },
   "source": [
    "Визуализируйте данные в проекции на первые две главные компоненты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTelxYX1_RiG"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, s=20, cmap='viridis')\n",
    "plt.xlabel('Первая главная компонента')\n",
    "plt.ylabel('Вторая главная компонента')\n",
    "plt.title('Визуализация данных в проекции на первые две главные компоненты')\n",
    "plt.colorbar(label='Активность')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-VEuzlq_RiH"
   },
   "source": [
    "**Вопрос 3:** (0.5 баллов)\n",
    "\n",
    "Если все получилось правильно, Вы увидите сколько-то кластеров, почти идеально отделенных друг от друга. Какие виды активности входят в эти кластеры?<br>\n",
    "\n",
    "**Ответ:**\n",
    "- 1 кластер: все 6 активностей\n",
    "- **2 кластера: (ходьба, подъем вверх по лестнице, спуск по лестнице) и (сидение, стояние, лежание)**\n",
    "- 3 кластера: (ходьба), (подъем вверх по лестнице, спуск по лестнице) и (сидение, стояние, лежание)\n",
    "- 6 кластеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqxchwSa_RiH"
   },
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibboiQZB_RiH"
   },
   "source": [
    "**Задание 1.** (1 балл)\n",
    "\n",
    "Сделайте кластеризацию данных методом `KMeans` (собственная имплементация и готовая реализация), обучив модель на данных со сниженной за счет PCA размерностью. В данном случае мы подскажем, что нужно искать именно 6 кластеров, но в общем случае мы не будем знать, сколько кластеров надо искать.\n",
    "\n",
    "Параметры:\n",
    "\n",
    "- **n_clusters** = n_classes (число уникальных меток целевого класса)\n",
    "- **n_init** = 100\n",
    "- **random_state** = RANDOM_STATE (для воспроизводимости результата)\n",
    "\n",
    "Остальные параметры со значениями по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yjOfGbK4_RiH"
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=n_classes, n_init=100, random_state=RANDOM_STATE)\n",
    "cluster_labels = kmeans.fit_predict(X_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_Jg_aVa_RiH"
   },
   "source": [
    "Визуализируйте данные в проекции на первые две главные компоненты. Раскрасьте точки в соответствии с полученными метками кластеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D0gGgz-u_RiH"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, s=20, cmap='viridis')\n",
    "plt.xlabel('Первая главная компонента')\n",
    "plt.ylabel('Вторая главная компонента')\n",
    "plt.title('Кластеризация KMeans (6 кластеров)')\n",
    "plt.colorbar(label='Кластер')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2KvsJI4_RiH"
   },
   "source": [
    "Посмотрите на соответствие между метками кластеров и исходными метками классов и на то, какие виды активностей алгоритм `KMeans` путает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fq7XwSt6_RiH"
   },
   "outputs": [],
   "source": [
    "tab = pd.crosstab(y, cluster_labels, margins=True)\n",
    "tab.index = ['ходьба', 'подъем вверх по лестнице',\n",
    "             'спуск по лестнице', 'сидение', 'стояние', 'лежание', 'все']\n",
    "tab.columns = ['cluster' + str(i + 1) for i in range(6)] + ['все']\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-Vv-gTq_RiH"
   },
   "source": [
    "max_fractions = []\n",
    "activity_names = ['ходьба', 'подъем вверх по лестнице', 'спуск по лестнице', \n",
    "                  'сидение', 'стояние', 'лежание']\n",
    "for i in range(6):\n",
    "    class_counts = tab.iloc[i, :6].values\n",
    "    max_fraction = class_counts.max() / tab.iloc[i, 6]\n",
    "    max_fractions.append(max_fraction)\n",
    "    print(f\"{activity_names[i]}: максимальная доля = {max_fraction:.4f}\")\n",
    "\n",
    "best_activity_idx = np.argmax(max_fractions)\n",
    "print(f\"\\nЛучше всего отделилась активность: {activity_names[best_activity_idx]} (доля = {max_fractions[best_activity_idx]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xb_L2peY_RiH"
   },
   "source": [
    "Видно, что kMeans не очень хорошо отличает только активности друг от друга. Используйте метод локтя, чтобы выбрать оптимальное количество кластеров. Параметры алгоритма и данные используем те же, что раньше, меняем только `n_clusters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ji0_1Ypg_RiH"
   },
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for k in tqdm(range(1, n_classes + 1)):\n",
    "    kmeans_k = KMeans(n_clusters=k, n_init=100, random_state=RANDOM_STATE)\n",
    "    kmeans_k.fit(X_pca)\n",
    "    inertia.append(kmeans_k.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, n_classes + 1), inertia, marker='o')\n",
    "plt.xlabel('Количество кластеров (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Метод локтя для выбора оптимального количества кластеров')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dPsQlI1_RiI"
   },
   "source": [
    "**Вопрос 5:** (1 балл)\n",
    "\n",
    "Какое количество кластеров оптимально выбрать, согласно методу локтя?<br>\n",
    "\n",
    "**Ответ:**\n",
    "- 1\n",
    "- **2**\n",
    "- 3\n",
    "- 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAKDC1za_RiI"
   },
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMmwpUYn_RiI"
   },
   "source": [
    "Попробуем еще один метод кластеризации, который описывался в статье – агломеративную кластеризацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F7YX7ZZ1_RiI"
   },
   "outputs": [],
   "source": [
    "ag = AgglomerativeClustering(n_clusters=n_classes,\n",
    "                             linkage='ward').fit(X_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFTPZ5hP_RiI"
   },
   "source": [
    "Посчитайте Adjusted Rand Index (`sklearn.metrics`) для получившегося разбиения на кластеры и для `KMeans` с параметрами из задания к 4 вопросу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lAoredcI_RiI"
   },
   "outputs": [],
   "source": [
    "ari_kmeans = metrics.adjusted_rand_score(y, cluster_labels)\n",
    "ari_agglomerative = metrics.adjusted_rand_score(y, ag.labels_)\n",
    "\n",
    "print(f\"Adjusted Rand Index для KMeans: {ari_kmeans:.4f}\")\n",
    "print(f\"Adjusted Rand Index для Agglomerative Clustering: {ari_agglomerative:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bd7Z-qsG_RiI"
   },
   "source": [
    "**Вопрос 6:** (1 балл)\n",
    "\n",
    "Отметьте все верные утверждения.<br>\n",
    "\n",
    "**Варианты:**\n",
    "- Согласно ARI, KMeans справился с кластеризацией хуже, чем Agglomerative Clustering\n",
    "- **Для ARI не имеет значения какие именно метки присвоены кластерам, имеет значение только разбиение объектов на кластеры**\n",
    "- **В случае случайного разбиения на кластеры ARI будет близок к нулю**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xq2mWpyN_RiM"
   },
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-tv7JUo_RiM"
   },
   "source": [
    "Можно заметить, что задача не очень хорошо решается именно как задача кластеризации, если выделять несколько кластеров (> 2). Давайте теперь решим задачу классификации, вспомнив, что данные у нас размечены.  \n",
    "\n",
    "Для классификации используйте метод опорных векторов – класс `sklearn.svm.LinearSVC`. Мы в курсе отдельно не рассматривали этот алгоритм, но он очень известен, почитать про него можно, например, в материалах Евгения Соколова –  [тут](https://github.com/esokolov/ml-course-msu/blob/master/ML16/lecture-notes/Sem11_linear.pdf).\n",
    "\n",
    "Настройте для `LinearSVC` гиперпараметр `C` с помощью `GridSearchCV`.\n",
    "\n",
    "- Обучите новый `StandardScaler` на обучающей выборке (со всеми исходными признаками), прмиените масштабирование к тестовой выборке\n",
    "- В `GridSearchCV` укажите  cv=3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coxyYzt7_RiM"
   },
   "outputs": [],
   "source": [
    "scaler_train = StandardScaler()\n",
    "X_train_scaled = scaler_train.fit_transform(X_train)\n",
    "X_test_scaled = scaler_train.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AxnfPkdr_RiM"
   },
   "outputs": [],
   "source": [
    "svc = LinearSVC(random_state=RANDOM_STATE)\n",
    "svc_params = {'C': [0.001, 0.01, 0.1, 1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQG_k9ur_RiM"
   },
   "outputs": [],
   "source": [
    "best_svc = GridSearchCV(svc, svc_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "best_svc.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Liwa-Fy_RiM"
   },
   "outputs": [],
   "source": [
    "print(f\"Лучший параметр C: {best_svc.best_params_['C']}\")\n",
    "print(f\"Лучший score на кросс-валидации: {best_svc.best_score_:.4f}\")\n",
    "print(f\"\\nРезультаты для всех значений C:\")\n",
    "for mean_score, params in zip(best_svc.cv_results_['mean_test_score'], best_svc.cv_results_['params']):\n",
    "    print(f\"  C={params['C']}: {mean_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vWEPCyU_RiN"
   },
   "source": [
    "**Вопрос 7** (0.5 баллов)\n",
    "\n",
    "Какое значение гиперпараметра `C` было выбрано лучшим по итогам кросс-валидации?<br>\n",
    "\n",
    "**Ответ:**\n",
    "- 0.001\n",
    "- 0.01\n",
    "- **0.1**\n",
    "- 1\n",
    "- 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sktOYTSI_RiN"
   },
   "outputs": [],
   "source": [
    "y_predicted = best_svc.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JcG7bYFZ_RiN"
   },
   "outputs": [],
   "source": [
    "tab = pd.crosstab(y_test, y_predicted, margins=True)\n",
    "tab.index = ['ходьба', 'подъем вверх по лестнице', 'спуск по лестнице',\n",
    "             'сидение', 'стояние', 'лежание', 'все']\n",
    "tab.columns = tab.index\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, precision_score, recall_score\n",
    "\n",
    "report = classification_report(y_test, y_predicted, \n",
    "                            target_names=['ходьба', 'подъем вверх по лестнице', \n",
    "                                        'спуск по лестнице', 'сидение', 'стояние', 'лежание'],\n",
    "                            output_dict=True)\n",
    "print(classification_report(y_test, y_predicted, \n",
    "                            target_names=['ходьба', 'подъем вверх по лестнице', \n",
    "                                        'спуск по лестнице', 'сидение', 'стояние', 'лежание']))\n",
    "\n",
    "activity_names = ['ходьба', 'подъем вверх по лестнице', 'спуск по лестнице', \n",
    "                  'сидение', 'стояние', 'лежание']\n",
    "precisions = [report[activity]['precision'] for activity in activity_names]\n",
    "recalls = [report[activity]['recall'] for activity in activity_names]\n",
    "\n",
    "worst_precision_idx = np.argmin(precisions)\n",
    "worst_recall_idx = np.argmin(recalls)\n",
    "\n",
    "print(f\"\\nХудшая точность (precision): {activity_names[worst_precision_idx]} = {precisions[worst_precision_idx]:.4f}\")\n",
    "print(f\"Худшая полнота (recall): {activity_names[worst_recall_idx]} = {recalls[worst_recall_idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58yUCEsi_RiN"
   },
   "source": [
    "**Вопрос 8:** (0.5 балл)\n",
    "\n",
    "Какой вид активности SVM определяет хуже всего в терминах точности? Полноты? <br>\n",
    "\n",
    "**Ответ:**\n",
    "- по точности – подъем вверх по лестнице, по полноте – лежание\n",
    "- **по точности – лежание, по полноте – сидение**\n",
    "- по точности – ходьба, по полноте – ходьба\n",
    "- по точности – сидение, по полноте – стояние"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train = PCA(n_components=0.9, random_state=RANDOM_STATE)\n",
    "X_train_pca = pca_train.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca_train.transform(X_test_scaled)\n",
    "\n",
    "svc_pca = LinearSVC(random_state=RANDOM_STATE)\n",
    "best_svc_pca = GridSearchCV(svc_pca, svc_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "best_svc_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "print(f\"Лучший параметр C (с PCA): {best_svc_pca.best_params_['C']}\")\n",
    "print(f\"Лучший score на кросс-валидации (с PCA): {best_svc_pca.best_score_:.4f}\")\n",
    "print(f\"Лучший score на кросс-валидации (без PCA): {best_svc.best_score_:.4f}\")\n",
    "diff_percent = (best_svc.best_score_ - best_svc_pca.best_score_) * 100\n",
    "print(f\"Разница: {diff_percent:.1f}%\")\n",
    "print(f\"Округлено до целых: {int(round(diff_percent))}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mHJSFUr_RiN"
   },
   "source": [
    "**Вопрос 9:** (1 балл)\n",
    "\n",
    "Какова разность между лучшим качеством (долей верных ответов) на кросс-валидации в случае всех 561 исходных признаков и во втором случае, когда применялся метод главных компонент? Округлите до целых процентов.<br>\n",
    "\n",
    "**Варианты:**\n",
    "- Качество одинаковое\n",
    "- **2%**\n",
    "- 4%\n",
    "- 10%\n",
    "- 20%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsXmWuyI_RiN"
   },
   "source": [
    "**Вопрос 10:** (1 балл)\n",
    "\n",
    "Выберите все верные утверждения:\n",
    "\n",
    "**Варианты:**\n",
    "- Метод главных компонент в данном случае позволил уменьшить время обучения модели, при этом качество (доля верных ответов на кросс-валидации) очень пострадало, более чем на 10%\n",
    "- **PCA можно использовать для визуализации данных, однако для этой задачи есть и лучше подходящие методы, например, tSNE. Зато PCA имеет меньшую вычислительную сложность**\n",
    "- **PCA строит линейные комбинации исходных признаков, и в некоторых задачах они могут плохо интерпретироваться человеком**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ЗАДАНИЕ 2: DBSCAN и tSNE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. Применение tSNE для снижения размерности...\")\n",
    "tsne = TSNE(n_components=2, random_state=RANDOM_STATE, perplexity=30, n_iter=1000)\n",
    "X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"Размерность после tSNE: {X_tsne.shape}\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, s=20, cmap='viridis')\n",
    "plt.xlabel('tSNE компонента 1')\n",
    "plt.ylabel('tSNE компонента 2')\n",
    "plt.title('Визуализация данных с помощью tSNE (истинные метки)')\n",
    "plt.colorbar(label='Активность')\n",
    "\n",
    "print(\"\\n2. Кластеризация с помощью DBSCAN на исходных данных...\")\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan_labels = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "n_clusters_dbscan = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "n_noise = list(dbscan_labels).count(-1)\n",
    "\n",
    "print(f\"Количество кластеров: {n_clusters_dbscan}\")\n",
    "print(f\"Количество шумовых точек: {n_noise}\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=dbscan_labels, s=20, cmap='viridis')\n",
    "plt.xlabel('tSNE компонента 1')\n",
    "plt.ylabel('tSNE компонента 2')\n",
    "plt.title(f'DBSCAN кластеризация (кластеров: {n_clusters_dbscan}, шум: {n_noise})')\n",
    "plt.colorbar(label='Кластер')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if n_clusters_dbscan > 0:\n",
    "    ari_dbscan = metrics.adjusted_rand_score(y, dbscan_labels)\n",
    "    print(f\"\\nAdjusted Rand Index для DBSCAN: {ari_dbscan:.4f}\")\n",
    "    \n",
    "    print(\"\\nСравнение методов кластеризации:\")\n",
    "    print(f\"  KMeans ARI: {ari_kmeans:.4f}\")\n",
    "    print(f\"  Agglomerative Clustering ARI: {ari_agglomerative:.4f}\")\n",
    "    print(f\"  DBSCAN ARI: {ari_dbscan:.4f}\")\n",
    "else:\n",
    "    print(\"\\nDBSCAN не нашел кластеров при данных параметрах.\")\n",
    "\n",
    "print(\"\\n3. Попробуем DBSCAN на данных с PCA...\")\n",
    "dbscan_pca = DBSCAN(eps=2.0, min_samples=10)\n",
    "dbscan_pca_labels = dbscan_pca.fit_predict(X_pca)\n",
    "\n",
    "n_clusters_dbscan_pca = len(set(dbscan_pca_labels)) - (1 if -1 in dbscan_pca_labels else 0)\n",
    "n_noise_pca = list(dbscan_pca_labels).count(-1)\n",
    "\n",
    "print(f\"Количество кластеров (на PCA данных): {n_clusters_dbscan_pca}\")\n",
    "print(f\"Количество шумовых точек: {n_noise_pca}\")\n",
    "\n",
    "if n_clusters_dbscan_pca > 0:\n",
    "    ari_dbscan_pca = metrics.adjusted_rand_score(y, dbscan_pca_labels)\n",
    "    print(f\"Adjusted Rand Index для DBSCAN (на PCA): {ari_dbscan_pca:.4f}\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1], c=dbscan_pca_labels, s=20, cmap='viridis')\n",
    "    plt.xlabel('Первая главная компонента')\n",
    "    plt.ylabel('Вторая главная компонента')\n",
    "    plt.title(f'DBSCAN на PCA данных (кластеров: {n_clusters_dbscan_pca})')\n",
    "    plt.colorbar(label='Кластер')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=dbscan_pca_labels, s=20, cmap='viridis')\n",
    "    plt.xlabel('tSNE компонента 1')\n",
    "    plt.ylabel('tSNE компонента 2')\n",
    "    plt.title('DBSCAN на PCA данных (визуализация через tSNE)')\n",
    "    plt.colorbar(label='Кластер')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ЗАДАНИЕ 2: DBSCAN и tSNE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. Применение tSNE для снижения размерности...\")\n",
    "tsne = TSNE(n_components=2, random_state=RANDOM_STATE, perplexity=30, n_iter=1000)\n",
    "X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"Размерность после tSNE: {X_tsne.shape}\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, s=20, cmap='viridis')\n",
    "plt.xlabel('tSNE компонента 1')\n",
    "plt.ylabel('tSNE компонента 2')\n",
    "plt.title('Визуализация данных с помощью tSNE (истинные метки)')\n",
    "plt.colorbar(label='Активность')\n",
    "\n",
    "print(\"\\n2. Кластеризация с помощью DBSCAN на исходных данных...\")\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan_labels = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "n_clusters_dbscan = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "n_noise = list(dbscan_labels).count(-1)\n",
    "\n",
    "print(f\"Количество кластеров: {n_clusters_dbscan}\")\n",
    "print(f\"Количество шумовых точек: {n_noise}\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=dbscan_labels, s=20, cmap='viridis')\n",
    "plt.xlabel('tSNE компонента 1')\n",
    "plt.ylabel('tSNE компонента 2')\n",
    "plt.title(f'DBSCAN кластеризация (кластеров: {n_clusters_dbscan}, шум: {n_noise})')\n",
    "plt.colorbar(label='Кластер')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if n_clusters_dbscan > 0:\n",
    "    ari_dbscan = metrics.adjusted_rand_score(y, dbscan_labels)\n",
    "    print(f\"\\nAdjusted Rand Index для DBSCAN: {ari_dbscan:.4f}\")\n",
    "    \n",
    "    print(\"\\nСравнение методов кластеризации:\")\n",
    "    print(f\"  KMeans ARI: {ari_kmeans:.4f}\")\n",
    "    print(f\"  Agglomerative Clustering ARI: {ari_agglomerative:.4f}\")\n",
    "    print(f\"  DBSCAN ARI: {ari_dbscan:.4f}\")\n",
    "else:\n",
    "    print(\"\\nDBSCAN не нашел кластеров при данных параметрах.\")\n",
    "\n",
    "print(\"\\n3. Попробуем DBSCAN на данных с PCA...\")\n",
    "dbscan_pca = DBSCAN(eps=2.0, min_samples=10)\n",
    "dbscan_pca_labels = dbscan_pca.fit_predict(X_pca)\n",
    "\n",
    "n_clusters_dbscan_pca = len(set(dbscan_pca_labels)) - (1 if -1 in dbscan_pca_labels else 0)\n",
    "n_noise_pca = list(dbscan_pca_labels).count(-1)\n",
    "\n",
    "print(f\"Количество кластеров (на PCA данных): {n_clusters_dbscan_pca}\")\n",
    "print(f\"Количество шумовых точек: {n_noise_pca}\")\n",
    "\n",
    "if n_clusters_dbscan_pca > 0:\n",
    "    ari_dbscan_pca = metrics.adjusted_rand_score(y, dbscan_pca_labels)\n",
    "    print(f\"Adjusted Rand Index для DBSCAN (на PCA): {ari_dbscan_pca:.4f}\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1], c=dbscan_pca_labels, s=20, cmap='viridis')\n",
    "    plt.xlabel('Первая главная компонента')\n",
    "    plt.ylabel('Вторая главная компонента')\n",
    "    plt.title(f'DBSCAN на PCA данных (кластеров: {n_clusters_dbscan_pca})')\n",
    "    plt.colorbar(label='Кластер')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=dbscan_pca_labels, s=20, cmap='viridis')\n",
    "    plt.xlabel('tSNE компонента 1')\n",
    "    plt.ylabel('tSNE компонента 2')\n",
    "    plt.title('DBSCAN на PCA данных (визуализация через tSNE)')\n",
    "    plt.colorbar(label='Кластер')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGrbn-wE_RiN"
   },
   "source": [
    "**Задание 2.** (1 балл)\n",
    "\n",
    "Попробуйте использовать DBSCAN в качестве алгоритма кластеризации и метод понижения размерности tSNE.\n",
    "\n",
    "**Решение:**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
